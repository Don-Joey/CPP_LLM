,Mean win rate,Synthetic reasoning (abstract symbols) - EM,Synthetic reasoning (natural language) - F1,bAbI - EM,Dyck - EM,GSM8K - EM,MATH - Equivalent,MATH (chain-of-thoughts) - Equivalent (chain of thought),HumanEval (Code) - pass@1,LSAT - EM,LegalSupport - EM,Data imputation - EM,Entity matching - EM
J1-Jumbo v1 (178B),0.517,0.263,0.174,0.543,0.445,0.054,0.089,0.033,-,0.232,0.484,0.735,0.841
J1-Large v1 (7.5B),0.366,0.201,0.154,0.469,0.414,0.014,0.049,0.031,-,0.196,0.514,0.729,0.827
J1-Grande v1 (17B),0.478,0.247,0.154,0.458,0.696,0.054,0.08,0.045,-,0.188,0.504,0.729,0.831
J1-Grande v2 beta (17B),0.578,0.286,0.139,0.47,0.617,0.096,0.127,0.068,-,0.191,0.562,0.8,0.844
Jurassic-2 Jumbo (178B),0.754,0.393,0.144,0.521,0.709,0.225,0.196,0.086,-,0.219,0.639,0.841,0.79
Jurassic-2 Grande (17B),0.624,0.301,0.164,0.455,0.529,0.133,0.146,0.054,-,0.22,0.575,0.829,0.849
Jurassic-2 Large (7.5B),0.491,0.192,0.176,0.504,0.559,0.03,0.07,0.023,-,0.217,0.558,0.731,0.836
Luminous Base (13B),0.361,0.209,0,0.452,0.517,0.026,0.089,0.026,-,0.235,0.513,0.725,0.543
Luminous Extended (30B),0.429,0.225,0,0.475,0.666,0.067,0.111,0.035,-,0.188,0.517,0.722,0.635
Luminous Supreme (70B),0.574,0.312,0,0.504,0.729,0.112,0.149,0.057,-,0.212,0.53,0.758,0.707
Anthropic-LM v4-s3 (52B),0.721,0.432,0.259,0.461,0.849,0.171,0.198,0.162,-,0.213,0.624,0.733,0.71
BLOOM (176B),0.497,0.304,0.197,0.447,0.545,0.095,0.043,0.055,-,0.209,0.543,0.677,0.852
T0pp (11B),0.127,0,0.002,0,0.011,0,0,0,-,0.186,0.611,0.004,0
Cohere xlarge v20220609 (52.4B),0.508,0.194,0,0.486,0.594,0.07,0.135,0.054,-,0.2,0.558,0.785,0.823
Cohere large v20220720 (13.1B),0.277,0.128,0,0.36,0.531,0.018,0.073,0.035,-,0.193,0.491,0.71,0.713
Cohere medium v20220720 (6.1B),0.254,0.129,0,0.391,0.511,0.015,0.049,0.027,-,0.212,0.507,0.721,0.482
Cohere small v20220720 (410M),0.124,0.121,0,0.306,0.358,0.004,0.016,0.003,-,0.187,0.524,0.47,0.176
Cohere xlarge v20221108 (52.4B),0.504,0.229,0,0.439,0.587,0.1,0.132,0.063,-,0.204,0.526,0.803,0.812
Cohere medium v20221108 (6.1B),0.245,0.096,0,0.471,0.411,0.017,0.052,0.021,-,0.206,0.489,0.72,0.535
Cohere Command beta (6.1B),0.355,0.123,0.254,0.473,0.372,0.036,0.076,0.038,-,0.178,0.566,0.696,0.532
Cohere Command beta (52.4B),0.612,0.243,0.245,0.497,0.421,0.138,0.133,0.075,-,0.229,0.606,0.752,0.569
GPT-J (6B),0.286,0.174,0.199,0.459,0.337,0.036,0.111,0.042,-,0.175,0.479,0.673,0.194
GPT-NeoX (20B),0.512,0.204,0.167,0.468,0.747,0.053,0.141,0.071,-,0.191,0.515,0.705,0.82
Pythia (1B),0.116,-,-,0.379,-,-,-,-,-,-,-,-,-
Pythia (6.9B),0.387,0.139,0,0.479,0.652,0.014,0.091,0.048,-,0.196,0.521,0.644,0.824
Pythia (12B),0.411,0.176,0,0.491,0.798,0.032,0.1,0.068,-,0.183,0.491,0.683,0.78
T5 (11B),0.225,0.196,0.101,0.412,0.347,0.023,0,0,-,0.159,0.558,0.624,0.652
UL2 (20B),0.3,0.205,0.187,0.501,0.14,0.024,0,0,-,0.207,0.506,0.611,0.672
OPT (175B),0.457,0.225,0.248,0.507,0.494,0.04,0.065,0.026,-,0.22,0.532,0.722,0.374
OPT (66B),0.295,0.193,0.213,0.408,0.471,0.018,0.048,0.029,-,0.175,0.527,0.718,0.466
LLaMA (7B),0.514,0.143,0,0.531,0.56,0.08,0.112,0.061,-,0.209,0.485,0.834,0.836
LLaMA (13B),0.635,0.214,0,0.561,0.686,0.154,0.134,0.11,-,0.187,0.587,0.824,0.859
LLaMA (30B),0.806,0.412,0,0.634,0.706,0.32,0.197,0.223,-,0.213,0.638,0.844,0.908
LLaMA (65B),0.83,0.438,0.432,0.677,0.65,0.466,0.224,0.253,-,0.213,0.591,0.822,0.861
Llama 2 (7B),0.62,0.222,0.26,0.55,0.658,0.133,0.107,0.099,-,0.148,0.532,0.801,0.851
Llama 2 (13B),0.757,0.324,0.271,0.584,0.624,0.245,0.145,0.122,-,0.235,0.591,0.844,0.528
Llama 2 (70B),0.867,0.489,0.472,0.705,0.742,0.484,0.261,0.33,-,0.235,0.585,0.838,0.732
Alpaca (7B),0.46,0.155,0.215,0.503,0.524,0.012,0.104,0.028,-,0.222,0.483,0.735,0.853
Vicuna v1.3 (7B),0.554,0.179,0.236,0.51,0.622,0.134,0.088,0.076,-,0.183,0.605,0.708,0.848
Vicuna v1.3 (13B),0.701,0.234,0.296,0.533,0.686,0.226,0.12,0.122,-,0.209,0.589,0.714,0.879
Mistral v0.1 (7B),0.833,0.451,0.392,0.593,0.696,0.381,0.209,0.293,-,0.213,0.585,0.795,0.938
TNLG v2 (530B),0.763,0.362,0.243,0.481,0.753,0.146,0.155,0.114,-,0.228,0.58,0.811,0.881
TNLG v2 (6.7B),0.415,0.232,0.247,0.411,0.554,0.018,0.068,0.023,-,0.19,0.504,0.826,0.694
davinci (175B),0.508,0.236,0.165,0.462,0.668,0.09,0.099,0.043,-,0.191,0.496,0.836,0.603
curie (6.7B),0.291,0.223,0.149,0.415,0.47,0.016,0.05,0.023,-,0.18,0.49,0.811,0.453
babbage (1.3B),0.278,0.16,0.12,0.348,0.473,0.007,0.048,0.009,-,0.261,0.492,0.599,0.632
ada (350M),0.123,0.1,0.088,0.306,0.406,0.006,0.046,0.006,-,0.188,0.372,0.582,0.349
text-davinci-003,0.946,0.502,0.734,0.653,0.751,0.506,0.39,0.449,-,0.233,0.622,0.839,0.93
text-davinci-002,0.897,0.488,0.623,0.618,0.603,0.415,0.328,0.381,-,0.229,0.615,0.842,0.931
text-curie-001,0.288,0.19,0.221,0.384,0.41,0.006,0.045,0.015,-,0.172,0.442,0.791,0.852
text-babbage-001,0.229,0.123,0.212,0.289,0.231,0,0.016,0.007,-,0.19,0.517,0.704,0.734
text-ada-001,0.217,0.063,0.145,0.226,0.161,0.004,0.02,0.001,-,0.213,0.515,0.597,0.808
code-davinci-002,0.785,0.54,0.684,0.686,0.805,0.568,0.41,0.433,0.463,0,0,-,-
code-cushman-001 (12B),0.37,0.341,0.164,0.481,0.451,0.049,0.099,0.072,0.317,0,0,-,-
gpt-3.5-turbo-0301,0.825,0.45,0.631,0.515,0.172,0.531,0.488,0.689,-,0.252,0.628,0.778,0.943
gpt-3.5-turbo-0613,0.684,0.509,0.586,0.528,0.01,0.469,0.453,0.719,-,0.161,0.468,0.836,0.918
RedPajama-INCITE-Base-v1 (3B),0.367,0.154,0,0.466,0.53,0.01,0.059,0.032,-,0.213,0.513,0.828,0.533
RedPajama-INCITE-Instruct-v1 (3B),0.352,0.142,0,0.522,0.708,0.011,0.06,0.004,-,0.17,0.485,0.752,0.828
RedPajama-INCITE-Base (7B),0.323,0.137,0,0.46,0.528,0.021,0.1,0.052,-,0.178,0.517,0.706,0.554
RedPajama-INCITE-Instruct (7B),0.5,0.184,0,0.545,0.546,0.016,0.058,0.028,-,0.243,0.569,0.772,0.843
MPT (30B),0.806,0.335,0.228,0.55,0.634,0.164,0.178,0.124,-,0.248,0.564,0.855,0.897
MPT-Instruct (30B),0.753,0.35,0.33,0.517,0.624,0.344,0.127,0.125,-,0.213,0.538,0.826,0.895
Falcon (7B),0.352,0.1,0.144,0.415,0.458,0.04,0.108,0.042,-,0.204,0.511,0.725,0.602
Falcon-Instruct (7B),0.34,0.037,0.1,0.424,0.192,0.052,0.069,0.03,-,0.204,0.452,0.836,0.824
Falcon (40B),0.722,0.238,0.139,0.576,0.534,0.25,0.21,0.13,-,0.213,0.605,0.83,0.847
Falcon-Instruct (40B),0.628,0.216,0.183,0.606,0.364,0.338,0.181,0.137,-,0.183,0.605,0.727,0.872
GLM (130B),0.372,0.252,0.254,0.443,0.549,0.061,0,0.059,-,0.193,0.451,0.66,0.472
InstructPalmyra (30B),0.471,0.231,0.247,0.468,0.447,0.063,0.099,0.039,-,0.187,0.492,0.833,0.77
Palmyra X (43B),0.891,0.504,0.576,0.702,0.579,0.633,0.301,0.38,-,0.225,0.623,0.824,0.966
YaLM (100B),0.205,0.056,0.061,0.346,0.633,0,0,0,-,0.23,0.484,0.419,0.176
