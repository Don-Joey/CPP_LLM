,Mean win rate,The Pile - BPB,TwitterAAE - BPB,ICE - BPB,BLiMP - EM
J1-Jumbo v1 (178B),0.642,0.545,2.18,0.849,0.811
J1-Large v1 (7.5B),0.461,0.645,2.245,0.895,0.806
J1-Grande v1 (17B),0.51,0.6,2.205,0.868,0.803
J1-Grande v2 beta (17B),0.58,0.602,2.156,0.836,0.805
Jurassic-2 Jumbo (178B),0.742,0.533,2.121,0.799,0.81
Jurassic-2 Grande (17B),0.658,0.593,2.137,0.83,0.809
Jurassic-2 Large (7.5B),0.585,0.639,2.179,0.865,0.816
Anthropic-LM v4-s3 (52B),0.763,0.597,2.109,0.822,0.829
BLOOM (176B),0.796,0.571,1.986,0.715,0.819
Cohere xlarge v20220609 (52.4B),0.526,0.757,2.305,0.875,0.83
Cohere large v20220720 (13.1B),0.509,0.811,2.324,0.916,0.833
Cohere medium v20220720 (6.1B),0.369,0.845,2.341,0.954,0.823
Cohere small v20220720 (410M),0.127,0.996,2.525,1.112,0.793
Cohere xlarge v20221108 (52.4B),0.512,0.741,2.325,0.923,0.832
Cohere medium v20221108 (6.1B),0.366,0.858,2.428,1.009,0.832
Cohere Command beta (6.1B),0.159,0.875,2.61,1.024,0.79
Cohere Command beta (52.4B),0.281,0.781,2.73,0.943,0.805
GPT-J (6B),0.892,0.49,1.989,0.752,0.834
GPT-NeoX (20B),0.946,0.466,1.943,0.742,0.839
OPT (175B),0.892,0.592,1.81,0.741,0.831
OPT (66B),0.817,0.618,1.85,0.764,0.827
TNLG v2 (530B),0.559,0.61,2.245,0.85,0.826
TNLG v2 (6.7B),0.57,0.704,2.323,0.918,0.835
davinci (175B),0.652,0.713,2.141,0.977,0.84
curie (6.7B),0.504,0.789,2.21,0.958,0.832
babbage (1.3B),0.42,0.866,2.291,1.048,0.833
ada (350M),0.237,0.96,2.395,1.136,0.818
text-davinci-003,0.672,0.576,2.192,0.838,0.823
text-davinci-002,0.685,0.578,2.147,0.823,0.812
text-curie-001,0.081,0.969,2.628,1.192,0.761
text-babbage-001,0.043,1.103,2.946,1.326,0.77
text-ada-001,0,1.61,3.505,1.975,0.728
