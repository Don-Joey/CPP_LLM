{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MMLU - EM</th>\n",
       "      <th>BoolQ - EM</th>\n",
       "      <th>NarrativeQA - F1</th>\n",
       "      <th>NaturalQuestions (closed-book) - F1</th>\n",
       "      <th>NaturalQuestions (open-book) - F1</th>\n",
       "      <th>QuAC - F1</th>\n",
       "      <th>HellaSwag - EM</th>\n",
       "      <th>OpenbookQA - EM</th>\n",
       "      <th>TruthfulQA - EM</th>\n",
       "      <th>MS MARCO (regular) - RR@10</th>\n",
       "      <th>MS MARCO (TREC) - NDCG@10</th>\n",
       "      <th>CNN/DailyMail - ROUGE-2</th>\n",
       "      <th>XSUM - ROUGE-2</th>\n",
       "      <th>IMDB - EM</th>\n",
       "      <th>CivilComments - EM</th>\n",
       "      <th>RAFT - EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>text-ada-001</th>\n",
       "      <td>0.238</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.238</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.232</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.503</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada (350M)</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.242</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.215</td>\n",
       "      <td>0.102</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cohere small v20220720 (410M)</th>\n",
       "      <td>0.264</td>\n",
       "      <td>0.457</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.348</td>\n",
       "      <td>0.217</td>\n",
       "      <td>-</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.578</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babbage (1.3B)</th>\n",
       "      <td>0.235</td>\n",
       "      <td>0.574</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.188</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text-babbage-001</th>\n",
       "      <td>0.229</td>\n",
       "      <td>0.451</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.284</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.449</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.499</td>\n",
       "      <td>0.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T0pp (11B)</th>\n",
       "      <td>0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.121</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.377</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pythia (6.9B)</th>\n",
       "      <td>0.236</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.142</td>\n",
       "      <td>0.539</td>\n",
       "      <td>0.296</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.213</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.928</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UL2 (20B)</th>\n",
       "      <td>0.291</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.349</td>\n",
       "      <td>0.144</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.193</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T5 (11B)</th>\n",
       "      <td>0.290</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.477</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.133</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YaLM (100B)</th>\n",
       "      <td>0.243</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.252</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.202</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               MMLU - EM  BoolQ - EM NarrativeQA - F1  \\\n",
       "text-ada-001                       0.238       0.464            0.238   \n",
       "ada (350M)                         0.243       0.581            0.326   \n",
       "Cohere small v20220720 (410M)      0.264       0.457            0.294   \n",
       "babbage (1.3B)                     0.235       0.574            0.491   \n",
       "text-babbage-001                   0.229       0.451            0.429   \n",
       "...                                  ...         ...              ...   \n",
       "T0pp (11B)                         0.407       0.000            0.151   \n",
       "Pythia (6.9B)                      0.236       0.631            0.528   \n",
       "UL2 (20B)                          0.291       0.746            0.083   \n",
       "T5 (11B)                           0.290       0.761            0.086   \n",
       "YaLM (100B)                        0.243       0.634            0.252   \n",
       "\n",
       "                               NaturalQuestions (closed-book) - F1  \\\n",
       "text-ada-001                                                 0.025   \n",
       "ada (350M)                                                   0.082   \n",
       "Cohere small v20220720 (410M)                                0.078   \n",
       "babbage (1.3B)                                               0.119   \n",
       "text-babbage-001                                             0.070   \n",
       "...                                                            ...   \n",
       "T0pp (11B)                                                   0.039   \n",
       "Pythia (6.9B)                                                0.142   \n",
       "UL2 (20B)                                                    0.204   \n",
       "T5 (11B)                                                     0.194   \n",
       "YaLM (100B)                                                  0.068   \n",
       "\n",
       "                              NaturalQuestions (open-book) - F1 QuAC - F1  \\\n",
       "text-ada-001                                              0.149     0.176   \n",
       "ada (350M)                                                0.365     0.242   \n",
       "Cohere small v20220720 (410M)                             0.309     0.219   \n",
       "babbage (1.3B)                                            0.451     0.273   \n",
       "text-babbage-001                                           0.33     0.284   \n",
       "...                                                         ...       ...   \n",
       "T0pp (11B)                                                 0.19     0.121   \n",
       "Pythia (6.9B)                                             0.539     0.296   \n",
       "UL2 (20B)                                                 0.349     0.144   \n",
       "T5 (11B)                                                  0.477     0.116   \n",
       "YaLM (100B)                                               0.227     0.162   \n",
       "\n",
       "                              HellaSwag - EM OpenbookQA - EM  TruthfulQA - EM  \\\n",
       "text-ada-001                           0.429           0.346            0.232   \n",
       "ada (350M)                             0.435            0.38            0.215   \n",
       "Cohere small v20220720 (410M)          0.483           0.348            0.217   \n",
       "babbage (1.3B)                         0.555           0.438            0.188   \n",
       "text-babbage-001                       0.561           0.452            0.233   \n",
       "...                                      ...             ...              ...   \n",
       "T0pp (11B)                                 -               -            0.377   \n",
       "Pythia (6.9B)                              -               -            0.213   \n",
       "UL2 (20B)                                  -               -            0.193   \n",
       "T5 (11B)                                   -               -            0.133   \n",
       "YaLM (100B)                                -               -            0.202   \n",
       "\n",
       "                              MS MARCO (regular) - RR@10  \\\n",
       "text-ada-001                                       0.134   \n",
       "ada (350M)                                         0.102   \n",
       "Cohere small v20220720 (410M)                          -   \n",
       "babbage (1.3B)                                     0.122   \n",
       "text-babbage-001                                   0.208   \n",
       "...                                                  ...   \n",
       "T0pp (11B)                                             -   \n",
       "Pythia (6.9B)                                          -   \n",
       "UL2 (20B)                                              -   \n",
       "T5 (11B)                                               -   \n",
       "YaLM (100B)                                            -   \n",
       "\n",
       "                              MS MARCO (TREC) - NDCG@10  \\\n",
       "text-ada-001                                      0.302   \n",
       "ada (350M)                                         0.29   \n",
       "Cohere small v20220720 (410M)                     0.304   \n",
       "babbage (1.3B)                                    0.317   \n",
       "text-babbage-001                                  0.449   \n",
       "...                                                 ...   \n",
       "T0pp (11B)                                            -   \n",
       "Pythia (6.9B)                                         -   \n",
       "UL2 (20B)                                             -   \n",
       "T5 (11B)                                              -   \n",
       "YaLM (100B)                                           -   \n",
       "\n",
       "                              CNN/DailyMail - ROUGE-2 XSUM - ROUGE-2  \\\n",
       "text-ada-001                                    0.136          0.034   \n",
       "ada (350M)                                       0.09          0.022   \n",
       "Cohere small v20220720 (410M)                   0.063          0.033   \n",
       "babbage (1.3B)                                  0.079          0.045   \n",
       "text-babbage-001                                0.151          0.046   \n",
       "...                                               ...            ...   \n",
       "T0pp (11B)                                      0.122           0.09   \n",
       "Pythia (6.9B)                                       -              -   \n",
       "UL2 (20B)                                        0.03          0.058   \n",
       "T5 (11B)                                        0.043          0.015   \n",
       "YaLM (100B)                                     0.017          0.021   \n",
       "\n",
       "                               IMDB - EM  CivilComments - EM  RAFT - EM  \n",
       "text-ada-001                       0.822               0.503      0.406  \n",
       "ada (350M)                         0.849               0.517      0.423  \n",
       "Cohere small v20220720 (410M)      0.578               0.501      0.492  \n",
       "babbage (1.3B)                     0.597               0.519      0.455  \n",
       "text-babbage-001                   0.913               0.499      0.509  \n",
       "...                                  ...                 ...        ...  \n",
       "T0pp (11B)                         0.207               0.234      0.118  \n",
       "Pythia (6.9B)                      0.928               0.511      0.502  \n",
       "UL2 (20B)                          0.337               0.521      0.404  \n",
       "T5 (11B)                           0.379               0.509      0.370  \n",
       "YaLM (100B)                        0.836               0.490      0.395  \n",
       "\n",
       "[67 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "content = pd.read_csv(\"/home/zhangqiyuan/bench_test/model_performance_core_acc.csv\", index_col=0)\n",
    "content = content.drop(columns=['Mean win rate'])\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data_to_csv(df1, all_dict):\n",
    "    for index, row in df1.iterrows():\n",
    "        #print(index, row)\n",
    "        if index not in all_dict.keys():\n",
    "            all_dict[index] = {}\n",
    "            for column_name in df1.columns:\n",
    "                row[column_name] = float(row[column_name]) if row[column_name] != \"-\" else \"-\"\n",
    "                #if column_name in all_dict[index].keys():\n",
    "                #    assert all_dict[index][column_name]==row[column_name], index+column_name\n",
    "                # Access the value for the current column in the current row\n",
    "                all_dict[index][column_name] = row[column_name]\n",
    "        else:\n",
    "            for column_name in df1.columns:\n",
    "                # Access the value for the current column in the current row\n",
    "                row[column_name] = float(row[column_name]) if row[column_name] != \"-\" else \"-\"\n",
    "                #if column_name in all_dict[index].keys():\n",
    "                #    assert all_dict[index][column_name]==row[column_name], index+column_name\n",
    "                all_dict[index][column_name] = row[column_name]\n",
    "    return all_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = [\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_core_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_target_acc.csv'\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_ir_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_knowledge_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_language_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_lite.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_qa_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_reasoning_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_summ_acc.csv\",\n",
    "    \"/home/zhangqiyuan/bench_test/model_performance_summ_metric.csv\"\n",
    "]\n",
    "\n",
    "all_dict={}\n",
    "for file in file_list:\n",
    "    df2 = pd.read_csv(file, index_col=0)\n",
    "    df2= df2.drop(columns=['Mean win rate'])\n",
    "    all_dict = append_data_to_csv(df2, all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(all_dict, orient='index').T\n",
    "\n",
    "# Specify your CSV file name\n",
    "csv_file = \"output.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(csv_file, header=True, index=True, index_label='Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranks = df.rank(axis=1, method='min', ascending=False, na_option='keep')\n",
    "df_ranks.to_csv(\"all_bencmark_rank_nan.csv\", header=True, index=True, index_label='Metric')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectgpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
